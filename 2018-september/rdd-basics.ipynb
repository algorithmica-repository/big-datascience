{"cells":[{"cell_type":"code","source":["data1 = [1,2,3,4,5,6,7,8,9,10]\nrdd = sc.parallelize(data1,4)\nprint(type(rdd))\nsquared_rdd = rdd.map(lambda x:x**2)\nres = squared_rdd.collect()\nprint(type(res))\nprint(res)\n\nfiltered_rdd = rdd.filter(lambda x:x%2==0)\nprint(type(filtered_rdd))\nprint(filtered_rdd.collect())\n\nflat_rdd = rdd.flatMap(lambda x:[x,x**3])\nprint(type(flat_rdd))\nprint(flat_rdd.collect())\n\nres = rdd.reduce(lambda x,y:x+y)\nprint(type(res))\nprint(res)\n\ndata2 = [1,2,2,2,2,3,3,3,3,4,5,6,7,7,7,8,8,8,9,10]\nrdd = sc.parallelize(data2,4)\ndistinct_rdd = rdd.distinct()\nprint(distinct_rdd.collect())\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;pyspark.rdd.RDD&apos;&gt;\n&lt;class &apos;list&apos;&gt;\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n&lt;class &apos;pyspark.rdd.PipelinedRDD&apos;&gt;\n[2, 4, 6, 8, 10]\n&lt;class &apos;pyspark.rdd.PipelinedRDD&apos;&gt;\n[1, 1, 2, 8, 3, 27, 4, 64, 5, 125, 6, 216, 7, 343, 8, 512, 9, 729, 10, 1000]\n&lt;class &apos;int&apos;&gt;\n55\n[8, 4, 1, 5, 9, 2, 10, 6, 3, 7]\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["events = [ ('Organizer1','A',20000), \n('Organizer1','B',10000),\n('Organizer2','C',30000),\n('Organizer1','D',20000),\n('Organizer3','E',10000),\n('Organizer1','F',20000),\n('Organizer1','G',20000),\n('Organizer2','H',10000),\n('Organizer3','I',20000),\n('Organizer1','J',20000)]\n        \nevents_rdd = sc.parallelize(events,4)\nprint(type(events_rdd))\nprint(events_rdd.collect())\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;pyspark.rdd.RDD&apos;&gt;\n[(&apos;Organizer1&apos;, &apos;A&apos;, 20000), (&apos;Organizer1&apos;, &apos;B&apos;, 10000), (&apos;Organizer2&apos;, &apos;C&apos;, 30000), (&apos;Organizer1&apos;, &apos;D&apos;, 20000), (&apos;Organizer3&apos;, &apos;E&apos;, 10000), (&apos;Organizer1&apos;, &apos;F&apos;, 20000), (&apos;Organizer1&apos;, &apos;G&apos;, 20000), (&apos;Organizer2&apos;, &apos;H&apos;, 10000), (&apos;Organizer3&apos;, &apos;I&apos;, 20000), (&apos;Organizer1&apos;, &apos;J&apos;, 20000)]\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["pair_rdd = events_rdd.map(lambda x: (x[0],x[2]))\nprint(type(pair_rdd))\nprint(pair_rdd.collect())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;pyspark.rdd.PipelinedRDD&apos;&gt;\n[(&apos;Organizer1&apos;, 20000), (&apos;Organizer1&apos;, 10000), (&apos;Organizer2&apos;, 30000), (&apos;Organizer1&apos;, 20000), (&apos;Organizer3&apos;, 10000), (&apos;Organizer1&apos;, 20000), (&apos;Organizer1&apos;, 20000), (&apos;Organizer2&apos;, 10000), (&apos;Organizer3&apos;, 20000), (&apos;Organizer1&apos;, 20000)]\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["grouped_rdd = pair_rdd.groupByKey()\nprint(grouped_rdd.collect())\n\ntotalbudgets_rdd = pair_rdd.reduceByKey(lambda x,y:x+y)\nprint(totalbudgets_rdd.collect())\n\ncoupled_values_rdd = pair_rdd.mapValues(lambda x: (x, 1))\nprint(coupled_values_rdd.collect())\n\ninterim_rdd = coupled_values_rdd.reduceByKey(lambda x,y: ((x[0] + y[0]), (x[1]+y[1])) )\nprint(interim_rdd.collect())\n\navg_rdd = interim_rdd.mapValues(lambda x: x[0]/x[1])\nprint(avg_rdd.collect())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&apos;Organizer3&apos;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f77f350add8&gt;), (&apos;Organizer1&apos;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f77f0214e48&gt;), (&apos;Organizer2&apos;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f77f0214dd8&gt;)]\n[(&apos;Organizer3&apos;, 30000), (&apos;Organizer1&apos;, 110000), (&apos;Organizer2&apos;, 40000)]\n[(&apos;Organizer1&apos;, (20000, 1)), (&apos;Organizer1&apos;, (10000, 1)), (&apos;Organizer2&apos;, (30000, 1)), (&apos;Organizer1&apos;, (20000, 1)), (&apos;Organizer3&apos;, (10000, 1)), (&apos;Organizer1&apos;, (20000, 1)), (&apos;Organizer1&apos;, (20000, 1)), (&apos;Organizer2&apos;, (10000, 1)), (&apos;Organizer3&apos;, (20000, 1)), (&apos;Organizer1&apos;, (20000, 1))]\n[(&apos;Organizer3&apos;, (30000, 2)), (&apos;Organizer1&apos;, (110000, 6)), (&apos;Organizer2&apos;, (40000, 2))]\n[(&apos;Organizer3&apos;, 15000.0), (&apos;Organizer1&apos;, 18333.333333333332), (&apos;Organizer2&apos;, 20000.0)]\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["lines = ['Spark is fun to try and its very fun to learn-','but you have to know how.','Spark uses Cache']\nlines_rdd = sc.parallelize(lines, 4)\nprint(lines_rdd.collect())\n\ndef normalize(line):\n\treturn line.strip().replace('-','').lower()\n  \nlines_normalized_rdd = lines_rdd.map(normalize) \nprint(lines_normalized_rdd.collect())\n\nwords_rdd = lines_normalized_rdd.flatMap(lambda line:line.split(' '))\nprint(words_rdd.collect())\n\nper_word_counts_rdd = words_rdd.map(lambda x: (x, 1))\nprint(per_word_counts_rdd.collect())\n\nword_freq_rdd = perwords_counts_rdd.reduceByKey(lambda x,y: x + y,2)\nprint(word_freq_rdd.collect())\n\n\n\n\n\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-2588495484467997&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     15</span> print<span class=\"ansiyellow\">(</span>per_word_counts_rdd<span class=\"ansiyellow\">.</span>collect<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     16</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 17</span><span class=\"ansiyellow\"> </span>word_freq_rdd <span class=\"ansiyellow\">=</span> words_counts_rdd<span class=\"ansiyellow\">.</span>reduceByKey<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> x<span class=\"ansiyellow\">,</span>y<span class=\"ansiyellow\">:</span> x <span class=\"ansiyellow\">+</span> y<span class=\"ansiyellow\">,</span><span class=\"ansicyan\">2</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     18</span> print<span class=\"ansiyellow\">(</span>word_freq_rdd<span class=\"ansiyellow\">.</span>collect<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     19</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;words_counts_rdd&apos; is not defined</div>"]}}],"execution_count":5}],"metadata":{"name":"rdd-basics","notebookId":2805823348641928},"nbformat":4,"nbformat_minor":0}
