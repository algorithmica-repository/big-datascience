<?xml version="1.0" encoding="UTF-8"?>

<coordinator-app name="add-partition-coord" frequency="${coord:hours(1)}"
                 start="${jobStart}" end="${jobEnd}"
                 timezone="UTC"
                 xmlns="uri:oozie:coordinator:0.1">
  <datasets>
    <dataset name="tweets" frequency="${coord:hours(1)}"
             initial-instance="${initialDataset}" timezone="America/Los_Angeles">
      <uri-template>hdfs://hadoop1:8020/user/flume/tweets/${YEAR}/${MONTH}/${DAY}/${HOUR}</uri-template>
      <done-flag></done-flag>
    </dataset>
  </datasets>
  <input-events>
    <data-in name="input" dataset="tweets">
      <instance>${coord:current(coord:tzOffset() / 60)}</instance>
    </data-in>
    <data-in name="readyIndicator" dataset="tweets">
      <!-- I've done something here that is a little bit of a hack. Since Flume
           doesn't have a good mechanism for notifying an application of when it has
           rolled to a new directory, we can just use the next directory as an
           input event, which instructs Oozie not to kick off a coordinator
           action until the next dataset starts being available. -->
      <instance>${coord:current(1 + (coord:tzOffset() / 60))}</instance>
    </data-in>
  </input-events>
  <action>
    <workflow>
      <app-path>${workflowRoot}/hive-action.xml</app-path>
      <configuration>
        <property>
          <name>wfInput</name>
          <value>${coord:dataIn('input')}</value>
        </property>
        <property>
          <name>dateHour</name>
          <value>${coord:formatTime(coord:dateOffset(coord:nominalTime(), tzOffset, 'HOUR'), 'yyyyMMddHH')}</value>
        </property>
      </configuration>
    </workflow>
  </action>
</coordinator-app>
